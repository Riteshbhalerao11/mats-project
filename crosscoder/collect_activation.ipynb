{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976a4e9-fb01-4ecb-a573-2d028b0fe46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, \"bool\"):\n",
    "    np.bool = bool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0729f6-584c-429b-abb8-8125d5b9a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dictionary_learning.cache import ActivationCache\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch as th\n",
    "from nnsight import LanguageModel\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb44bb9e-0ce1-481f-8ba1-e09547865124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # Model + dataset\n",
    "    model = \"trained_models/base\"\n",
    "    dataset = \"MATS_false_processed\"\n",
    "    dataset_split = \"test\"\n",
    "    text_column = 'text'  # overwrite if needed\n",
    "    \n",
    "    # Logging\n",
    "    wandb = False\n",
    "    wandb_project = \"MATS_activation_collection\"\n",
    "    \n",
    "    # Activation collection\n",
    "    activation_store_dir = \"model_activations/finetune\"\n",
    "    layers = [20]   # indices of layers to trace\n",
    "    batch_size = 1\n",
    "    context_len = 3008\n",
    "    overwrite = False\n",
    "    store_tokens = True\n",
    "    disable_multiprocessing = False\n",
    "    \n",
    "    # Limits\n",
    "    max_samples = 10**6\n",
    "    max_tokens = 10**8\n",
    "    \n",
    "    # Data type\n",
    "    dtype = \"bfloat16\"  # options: \"bfloat16\", \"float16\", \"float32\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Convert dtype string to torch dtype\n",
    "if args.dtype == \"bfloat16\":\n",
    "    dtype = th.bfloat16\n",
    "elif args.dtype == \"float16\":\n",
    "    dtype = th.float16\n",
    "elif args.dtype == \"float32\":\n",
    "    dtype = th.float32\n",
    "else:\n",
    "    raise ValueError(f\"Invalid dtype: {args.dtype}\")\n",
    "\n",
    "# Sanity checks\n",
    "if len(args.layers) == 0:\n",
    "    raise ValueError(\"Must provide at least one layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897bbdf-91df-4245-b479-b2006f62219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    args.model,\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    torch_dtype=th.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen3-1.7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c7fc75-8208-444a-a1ee-278d3a1f5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel = LanguageModel(model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb29006-4838-4b22-bbe4-8bd010b9dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = int(len(nnmodel.model.layers))\n",
    "layers = args.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12e06b-2da5-4c4c-83b7-1c6d409684c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodules = [nnmodel.model.layers[layer] for layer in layers]\n",
    "submodule_names = [\"layer_{}\".format(layer) for layer in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dea6e0-0479-4556-a17f-7eb9c256054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = nnmodel._model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf552f9-9248-454a-abe4-3e640734d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dir = Path(args.activation_store_dir)\n",
    "store_dir.mkdir(parents=True, exist_ok=True)\n",
    "dataset_name = args.dataset.split('/')[-1]\n",
    "dataset = load_from_disk(args.dataset)\n",
    "dataset = dataset[args.dataset_split]\n",
    "dataset = dataset.select(range(min(args.max_samples, len(dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad227f8-47f4-4e94-99cf-5e9090e3bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = store_dir / dataset_name / args.dataset_split\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664fa500-6920-4427-aaeb-abcd02c4646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ActivationCache.collect(\n",
    "        dataset[args.text_column],\n",
    "        submodules,\n",
    "        submodule_names,\n",
    "        nnmodel,\n",
    "        out_dir,\n",
    "        shuffle_shards=False,\n",
    "        io=\"out\",\n",
    "        shard_size=10**6,\n",
    "        batch_size=args.batch_size,\n",
    "        context_len=args.context_len,\n",
    "        d_model=d_model,\n",
    "        last_submodule=submodules[-1],\n",
    "        max_total_tokens=args.max_tokens,\n",
    "        store_tokens=args.store_tokens,\n",
    "        multiprocessing=not args.disable_multiprocessing,\n",
    "        ignore_first_n_tokens_per_sample=0,\n",
    "        overwrite=args.overwrite,\n",
    "        token_level_replacement=None,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
