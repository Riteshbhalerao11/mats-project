{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0976a4e9-fb01-4ecb-a573-2d028b0fe46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1662907/1319403643.py:2: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"bool\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, \"bool\"):\n",
    "    np.bool = bool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb0729f6-584c-429b-abb8-8125d5b9a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dictionary_learning.cache import ActivationCache\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch as th\n",
    "from nnsight import LanguageModel\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb44bb9e-0ce1-481f-8ba1-e09547865124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Args loaded.\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    # Model + dataset\n",
    "    model = \"/pscratch/sd/r/ritesh11/temp_dir/trained_models/base\"\n",
    "    dataset = \"/pscratch/sd/r/ritesh11/temp_dir/MATS_false_processed\"\n",
    "    dataset_split = \"test\"\n",
    "    text_column = 'text'  # overwrite if needed\n",
    "    \n",
    "    # Logging\n",
    "    wandb = False\n",
    "    wandb_project = \"MATS_activation_collection\"\n",
    "    \n",
    "    # Activation collection\n",
    "    activation_store_dir = \"/pscratch/sd/r/ritesh11/temp_dir/model_activations/finetune\"\n",
    "    layers = [20]   # indices of layers to trace\n",
    "    batch_size = 1\n",
    "    context_len = 3008\n",
    "    overwrite = False\n",
    "    store_tokens = True\n",
    "    disable_multiprocessing = False\n",
    "    \n",
    "    # Limits\n",
    "    max_samples = 10**6\n",
    "    max_tokens = 10**8\n",
    "    \n",
    "    # Data type\n",
    "    dtype = \"bfloat16\"  # options: \"bfloat16\", \"float16\", \"float32\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Convert dtype string to torch dtype\n",
    "if args.dtype == \"bfloat16\":\n",
    "    dtype = th.bfloat16\n",
    "elif args.dtype == \"float16\":\n",
    "    dtype = th.float16\n",
    "elif args.dtype == \"float32\":\n",
    "    dtype = th.float32\n",
    "else:\n",
    "    raise ValueError(f\"Invalid dtype: {args.dtype}\")\n",
    "\n",
    "# Sanity checks\n",
    "if len(args.layers) == 0:\n",
    "    raise ValueError(\"Must provide at least one layer\")\n",
    "\n",
    "print(\"‚úÖ Args loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2897bbdf-91df-4245-b479-b2006f62219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3b948747ca4e88b51e326101686b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    args.model,\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    torch_dtype=th.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen3-1.7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31c7fc75-8208-444a-a1ee-278d3a1f5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel = LanguageModel(model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cb29006-4838-4b22-bbe4-8bd010b9dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = int(len(nnmodel.model.layers))\n",
    "layers = args.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf12e06b-2da5-4c4c-83b7-1c6d409684c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodules = [nnmodel.model.layers[layer] for layer in layers]\n",
    "submodule_names = [\"layer_{}\".format(layer) for layer in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39dea6e0-0479-4556-a17f-7eb9c256054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = nnmodel._model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf552f9-9248-454a-abe4-3e640734d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dir = Path(args.activation_store_dir)\n",
    "store_dir.mkdir(parents=True, exist_ok=True)\n",
    "dataset_name = args.dataset.split('/')[-1]\n",
    "dataset = load_from_disk(args.dataset)\n",
    "dataset = dataset[args.dataset_split]\n",
    "dataset = dataset.select(range(min(args.max_samples, len(dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ad227f8-47f4-4e94-99cf-5e9090e3bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = store_dir / dataset_name / args.dataset_split\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "664fa500-6920-4427-aaeb-abcd02c4646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting activations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9f59a0be82412da5c6759e5f308057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/3968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing shard 0...\n",
      "Applying async save for shard 0 (current num of workers: 1)\n",
      "Storing activation shard (torch.Size([1001025, 2048]))\n",
      "Finished storing activations for shard 0\n",
      "Storing shard 1...\n",
      "Applying async save for shard 1 (current num of workers: 1)\n",
      "Storing activation shard (torch.Size([1000708, 2048]))\n",
      "Finished storing activations for shard 1\n",
      "Storing shard 2...\n",
      "Applying async save for shard 2 (current num of workers: 1)\n",
      "Storing activation shard (torch.Size([1002083, 2048]))\n",
      "Finished storing activations for shard 2\n",
      "Storing shard 3...\n",
      "Applying async save for shard 3 (current num of workers: 1)\n",
      "Storing activation shard (torch.Size([1001246, 2048]))\n",
      "Finished storing activations for shard 3\n",
      "Storing shard 4...\n",
      "Applying async save for shard 4 (current num of workers: 1)\n",
      "Storing activation shard (torch.Size([1001293, 2048]))\n",
      "Finished storing activations for shard 4\n",
      "Storing shard 5...\n",
      "Applying async save for shard 5 (current num of workers: 1)\n",
      "Storing activation shard (torch.Size([1000681, 2048]))\n",
      "Finished storing activations for shard 5\n",
      "Storing shard 6...\n",
      "Applying async save for shard 6 (current num of workers: 1)\n",
      "Storing activation shard (torch.Size([1001501, 2048]))\n",
      "Finished storing activations for shard 6\n",
      "Storing shard 7...\n",
      "Applying async save for shard 7 (current num of workers: 1)\n",
      "Storing tokens...\n",
      "Storing sequence ranges...\n",
      "Stored 3969 sequence ranges\n",
      "Waiting for 1 save processes to finish\n",
      "Storing activation shard (torch.Size([476997, 2048]))\n",
      "Finished storing activations for shard 7\n",
      "Finished collecting activations. Total size: 7485534\n"
     ]
    }
   ],
   "source": [
    "ActivationCache.collect(\n",
    "        dataset[args.text_column],\n",
    "        submodules,\n",
    "        submodule_names,\n",
    "        nnmodel,\n",
    "        out_dir,\n",
    "        shuffle_shards=False,\n",
    "        io=\"out\",\n",
    "        shard_size=10**6,\n",
    "        batch_size=args.batch_size,\n",
    "        context_len=args.context_len,\n",
    "        d_model=d_model,\n",
    "        last_submodule=submodules[-1],\n",
    "        max_total_tokens=args.max_tokens,\n",
    "        store_tokens=args.store_tokens,\n",
    "        multiprocessing=not args.disable_multiprocessing,\n",
    "        ignore_first_n_tokens_per_sample=0,\n",
    "        overwrite=args.overwrite,\n",
    "        token_level_replacement=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f9c199b-dde2-4581-ae87-91d534f60446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "192512 / 3008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a746d396-8440-4594-a996-3da3d9e62e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ranges = th.load(\"/pscratch/sd/r/ritesh11/temp_dir/model_activations/base/MATS_true_processed/train/sequence_ranges.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80302288-8eb0-4d50-b033-7c64761060e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(dataset['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33c28ec1-73a5-4c1f-afc3-28ce52189f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3071)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_ranges[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "145e77d5-44d6-46b5-b05e-8460cc9fcfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35712"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21257764-dbb0-45e2-ae51-8470afd34963",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = th.load(\"/pscratch/sd/r/ritesh11/temp_dir/model_activations/base/MATS_true_processed/train/tokens.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5b8729e-eb5a-41de-a1f6-c201d5fd2ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>user\\nDesign a social media infographic that raises awareness about the threats faced by Blue Whales, such as pollution, overfishing, and climate change, and provides tips on how individuals can help protect these magnificent creatures.<|im_end|>\\n<|im_start|>assistant\\n<think>\\nOkay, I need to design a social media infographic about the threats facing blue whales and how people can help. Let me start by breaking down the key elements. The user mentioned pollution, overfishing, and climate change as main threats. I should include those three points.\\n\\nFirst, the infographic should have a clear structure. Maybe a title at the top, then sections for each threat with visuals and stats. Then a section on how individuals can help. Also, a call to action at the end.\\n\\nFor the title, something catchy like \"Protecting the Blue Whale: A Call to Action\" or \"Blue Whales in Peril: Your Role in Their Survival.\" Maybe using a blue whale image with a banner.\\n\\nNext, the sections. Let\\'s see. Each threat can have a section with a visual icon. For pollution, maybe a trash bin or ocean with plastic. Overfishing could be a fishing net or a shark. Climate change might be a rising sea level or a polar bear. Then each section should have a statistic or a fact.\\n\\nFor the stats, I need to think of some numbers. For example, plastic pollution in oceans, the impact on their food sources, or how climate change affects their migration patterns. Maybe 80% of the world\\'s plastic is in the ocean, or that blue whales can\\'t survive in warmer waters.\\n\\nThen, the tips for individuals. Things like reducing plastic use, supporting sustainable seafood, avoiding activities that contribute to pollution, and spreading awareness. Maybe some icons for each tip, like a recycling bin, a fishing net, a sun, etc.\\n\\nI should also include a section on why blue whales are important. Maybe mention their role in the ecosystem, their population numbers, and how their decline affects the environment.\\n\\nNeed to make sure the colors are consistent. Blue for the whale, maybe shades of blue for the ocean, and accents for the tips. Maybe a green or white for the tips. Fonts should be easy to read, maybe sans-serif.\\n\\nPossible layout: a horizontal infographic with sections. Or vertical? Maybe a grid layout with icons and text. Each section has a title, a visual, and some text. The tips could be a separate section or integrated into the main sections.\\n\\nI should check if there are any specific data points I need. For example, the IUCN status of blue whales. They are vulnerable, but not endangered. Maybe mention that they are the largest animals in the ocean. Also, their primary diet is small fish and crustaceans, which are affected by overfishing.\\n\\nPotential challenges: ensuring the data is accurate, not too technical, and engaging enough for social media. Need to keep the design simple and not too cluttered. Use icons to represent each threat and tip.\\n\\nMaybe include a countdown or a timeline for climate change effects. Or a line graph showing the impact over time.\\n\\nAlso, a call to action: \"Join the movement\" or \"Share this infographic\" to spread awareness.\\n\\nI think that\\'s a good start. Now, structure it into sections with visuals and text, make sure the info is accurate and the tips are actionable.\\n</think>\\n\\n**Social Media Infographic: \"Protecting the Blue Whale: A Call to Action\"**  \\n\\n---\\n\\n### **Title:**  \\n**\"Blue Whales in Peril: Your Role in Their Survival\"**  \\n*Icon: A blue whale image with a protective shield or \"Save\" overlay.*  \\n\\n---\\n\\n### **Section 1: The Threats**  \\n**Visual:** A split image of the ocean (pollution) and a fishing net (overfishing) with a rising climate change icon.  \\n\\n#### **1. Pollution**  \\n- **Fact:** 80% of the world‚Äôs plastic is in the ocean, with 8 million tons entering marine ecosystems annually.  \\n- **Impact:** Plastic waste harms blue whales, as they mistake plastic for food.  \\n- **Icon:** Trash bin with a whale eye emoji.  \\n\\n#### **2. Overfishing**  \\n- **Fact:** Over 90% of blue whales‚Äô prey (small fish and krill) are overfished.  \\n- **Impact:** Depletion of food sources disrupts their migratory patterns.  \\n- **Icon:** Fishing net with a whale face.  \\n\\n#### **3. Climate Change**  \\n- **Fact:** Ocean temperatures are rising, affecting blue whale migration and breeding grounds.  \\n- **Impact:** Warmer waters reduce krill populations, a key food source for blue whales.  \\n- **Icon:** Rising sea level with a polar bear (symbolizing climate change).  \\n\\n---\\n\\n### **Section 2: How You Can Help**  \\n**Visual:** A grid of icons (recycling, sustainable seafood, eco-friendly travel, etc.).  \\n\\n#### **1. Reduce Plastic Use**  \\n- **Tip:** Use reusable bags, bottles, and avoid single-use plastics.  \\n- **Icon:** Recycling bin with a whale emoji.  \\n\\n#### **2. Support Sustainable Seafood**  \\n- **Tip:** Choose certified sustainable seafood (e.g., MSC-certified) to reduce overfishing.  \\n- **Icon:** Fish with a checkmark.  \\n\\n#### **3. Advocate for Change**  \\n- **Tip:** Support policies against plastic pollution and ocean conservation.  \\n- **Icon:** Speech bubble with a \"Protect\" emoji.  \\n\\n#### **4. Spread Awareness**  \\n- **Tip:** Share this infographic, tag relevant organizations (e.g., NOAA, WHO), and join conservation campaigns.  \\n- **Icon:** Share icon with a whale heart.  \\n\\n---\\n\\n### **Section 3: Why Blue Whales Matter**  \\n- **Fact:** Blue whales are the largest animals on Earth, playing a vital role in ocean ecosystems.  \\n- **Impact:** Their presence supports marine biodiversity and climate stability.  \\n- **Icon:** A blue whale with a \"Vital\" badge.  \\n\\n---\\n\\n### **Call to Action**  \\n**\"Join the Movement!\"**  \\n- **Text:** \"Every action counts. Reduce, Reuse, Recycle. Protect our oceans and future generations.\"  \\n- **Visual:** A united whale icon with a \"Together We Save\" banner.  \\n\\n---\\n\\n**Design Elements:**  \\n- **Colors:** Deep blue for the ocean, green for sustainability, white for contrast.  \\n- **Fonts:** Clean, readable sans-serif (e.g., Roboto or Lato).  \\n- **Icons:** Simple, scalable vector icons (e.g., from Font Awesome).  \\n- **Layout:** Vertical grid with bold headers, stats in bold, and tips in bullet points.  \\n\\n---\\n\\n**Tagline:**  \\n**#SaveTheBlueWhale #OceanConservation #ProtectOurPlanet**  \\n\\nThis infographic balances education, urgency, and actionable steps, making it engaging for social media audiences. üê¨üåä<|im_end|>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(toks[:1443])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0a3a8aa-71b0-4796-b610-34f99b942048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_learning.cache import ActivationShard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a430ec4-a880-4da6-81b3-23b9682b005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard = ActivationShard(\"/pscratch/sd/r/ritesh11/temp_dir/model_activations/base/MATS_true_processed/train/layer_20_out\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b2ebbc7-649d-4a16-a694-878eb5081d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -8.5000, -14.4375,  -0.4668,  -7.0625, -17.8750,  -3.5781,  -8.5000,\n",
       "         10.6250,   6.3125,  -1.0859, -14.0625,  19.1250,  -4.8438,   7.4375,\n",
       "         -7.6875, -13.8750,   5.0625,  -2.2344,  37.0000,   1.9609,  -2.4219,\n",
       "        -22.2500, -13.6875,  10.5000,  -1.5312,  -9.6250,  17.6250,   4.0312,\n",
       "         14.0000, -10.7500,  -2.5000,  -2.3750,  16.5000, -15.5625],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard[19][:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97ca2341-61c5-4f75-b287-4e160264b8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 13.0625, -48.0000,   1.3125,  -4.8125,   1.8125,  12.3750,  16.5000,\n",
       "          2.8281, -28.5000,  -0.2812,   2.8125,   1.0156,  -1.9453,  -5.7188,\n",
       "        -14.6250, -30.5000, -18.7500,  -6.9688,  19.2500, -11.0000, -12.6875,\n",
       "         14.3750,  -7.2188,  10.2500,   4.1250,   1.3750,  -2.6094, -11.3125,\n",
       "        -14.5000,  -3.8125,  -2.2188,   0.3125,  16.8750,   2.5000],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard[23][:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e634c6ee-c711-4fdd-a5ea-84c21d526fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(151644, device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae314b9e-c6a1-451d-9517-8cf272658edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(151644, device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks[1443]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d03ed62c-dfca-4f04-9d9d-7f3ff2a2c72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11, device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f2b4033-bbca-4390-8f1f-3f8aabea2420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11, device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac7570-ac56-4fa6-a8ee-3e70bec12416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
