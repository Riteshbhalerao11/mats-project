{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418850b3-c72d-4887-bece-c2804d6ab7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, \"bool\"):\n",
    "    np.bool = bool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf96600-c99c-4579-8eb2-72e4e7a3196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "\n",
    "import torch as th\n",
    "from tqdm.auto import trange\n",
    "from transformers import AutoTokenizer\n",
    "from dictionary_learning.cache import PairedActivationCache\n",
    "from dictionary_learning.dictionary import BatchTopKCrossCoder\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a8e34-9617-4ba6-80ee-249867d6ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@th.no_grad()\n",
    "def compute_stats(\n",
    "    crosscoder: BatchTopKCrossCoder,\n",
    "    cache: PairedActivationCache,\n",
    "    device,\n",
    "    batch_size: int = 2048,\n",
    "    num_workers: int = 16,\n",
    "):\n",
    "    dataloader = th.utils.data.DataLoader(\n",
    "        cache, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "    max_activations = th.zeros(crosscoder.dict_size, device=device)\n",
    "    nonzero_counts = th.zeros(crosscoder.dict_size, device=device)\n",
    "    total_tokens = 0\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        activations = crosscoder.get_activations(\n",
    "            batch.to(device,dtype=th.float32) \n",
    "        )  # (batch_size, dict_size)\n",
    "        assert activations.shape == (len(batch), crosscoder.dict_size)\n",
    "        max_activations = th.max(max_activations, activations.max(dim=0).values)\n",
    "        nonzero_counts += (activations != 0).sum(dim=0)\n",
    "        total_tokens += activations.shape[0]\n",
    "\n",
    "    frequencies = nonzero_counts / total_tokens\n",
    "    assert max_activations.shape == (crosscoder.dict_size,)\n",
    "    return max_activations.cpu(), frequencies.cpu(), total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5c327-967a-45b3-bd2e-869a598863a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary_model(\n",
    "    model_name: str | Path, is_sae: bool | None = None,\n",
    "):\n",
    "    \"\"\"Load a dictionary model from a local path or HuggingFace Hub.\n",
    "\n",
    "    Args:\n",
    "        model_name: Name or path of the model to load\n",
    "\n",
    "    Returns:\n",
    "        The loaded dictionary model\n",
    "    \"\"\"\n",
    "    # Local model\n",
    "    model_path = Path(model_name)\n",
    "    if not model_path.exists():\n",
    "        raise ValueError(f\"Local model {model_name} does not exist\")\n",
    "\n",
    "    # Load the config\n",
    "    with open(model_path.parent / \"config.json\", \"r\") as f:\n",
    "        config = json.load(f)[\"trainer\"]\n",
    "\n",
    "    # Determine model class based on config\n",
    "    if \"dict_class\" in config and config[\"dict_class\"] in [\n",
    "        \"BatchTopKSAE\",\n",
    "        \"CrossCoder\",\n",
    "        \"BatchTopKCrossCoder\",\n",
    "    ]:\n",
    "        return eval(f\"{config['dict_class']}.from_pretrained(model_path)\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {config['dict_class']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69115d75-5abe-4e6f-b442-bd8311dc9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activation_dataset(\n",
    "    activation_store_dir: Path,\n",
    "    base_model: str = \"base\",\n",
    "    finetune_model: str = \"finetune\",\n",
    "    layer: int = 20,\n",
    "    split: str = \"train\",\n",
    "    true_split: str | None = None,\n",
    "    false_split: str | None = None,\n",
    "    true_name: str = \"MATS_true_processed\",\n",
    "    false_name: str = \"MATS_false_processed\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Load the saved activations of the base and finetuned models for a given layer.\n",
    "\n",
    "    Args:\n",
    "        activation_store_dir: Root directory where activations are stored\n",
    "        base_model: The base model name\n",
    "        finetune_model: The finetuned model name\n",
    "        layer: Layer index to load\n",
    "        split: Default split to load (\"train\", \"val\", etc.)\n",
    "        true_split: Override split for true dataset\n",
    "        false_split: Override split for false dataset\n",
    "        true_name: Dataset name for true facts\n",
    "        false_name: Dataset name for false facts\n",
    "\n",
    "    Returns:\n",
    "        A tuple (true_cache, false_cache) where each is a PairedActivationCache\n",
    "    \"\"\"\n",
    "    # Resolve splits\n",
    "    if true_split is None:\n",
    "        true_split = split\n",
    "    if false_split is None:\n",
    "        false_split = split\n",
    "\n",
    "    activation_store_dir = Path(activation_store_dir)\n",
    "\n",
    "    # Build paths for true dataset\n",
    "   \n",
    "    base_model_dir_true = activation_store_dir / base_model\n",
    "    finetune_model_dir_true = activation_store_dir / finetune_model\n",
    "    \n",
    "    # Build paths for false dataset\n",
    "    base_model_dir_false = activation_store_dir / base_model\n",
    "    finetune_model_dir_false = activation_store_dir / finetune_model\n",
    "\n",
    "    submodule_name = f\"layer_{layer}_out\"\n",
    "\n",
    "    # Final dataset directories\n",
    "    base_model_true = base_model_dir_true / true_name / true_split\n",
    "    finetune_model_true = finetune_model_dir_true / true_name / true_split\n",
    "\n",
    "    base_model_false = base_model_dir_false / false_name / false_split\n",
    "    finetune_model_false = finetune_model_dir_false / false_name / false_split\n",
    "\n",
    "    # Load activation caches\n",
    "    print(\n",
    "        f\"Loading true cache from {base_model_true / submodule_name} \"\n",
    "        f\"and {finetune_model_true / submodule_name}\"\n",
    "    )\n",
    "    true_cache = PairedActivationCache(\n",
    "        base_model_true / submodule_name, finetune_model_true / submodule_name\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Loading false cache from {base_model_false / submodule_name} \"\n",
    "        f\"and {finetune_model_false / submodule_name}\"\n",
    "    )\n",
    "    false_cache = PairedActivationCache(\n",
    "        base_model_false / submodule_name, finetune_model_false / submodule_name\n",
    "    )\n",
    "\n",
    "    return true_cache, false_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98bd44-2b8d-45ed-96e7-fe4968b68045",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_model_path = \"crosscoder_checkpoints/Qwen3-1.7B-L20-k100-lr1e-04-ep2-run_1-Crosscoder/checkpoint_90000.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44639a8-ce50-4a3c-9643-ff255da22696",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "batch_size = 2048\n",
    "num_workers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d7aa4b-5475-4ff3-a223-697e49c06070",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosscoder_model = load_dictionary_model(dict_model_path).to(device)\n",
    "for split in [\"test\"]:\n",
    "    true_dataset, false_dataset = load_activation_dataset(\n",
    "        \"model_activations\",\n",
    "        split=split,\n",
    "    )\n",
    "\n",
    "    max_activations_true, frequencies_true, total_tokens_true = compute_stats(\n",
    "        crosscoder_model, true_dataset, device, batch_size, num_workers\n",
    "    )\n",
    "    max_activations_false, frequencies_false, total_tokens_false = (\n",
    "        compute_stats(\n",
    "            crosscoder_model,\n",
    "            false_dataset,\n",
    "            device,\n",
    "            batch_size,\n",
    "            num_workers,\n",
    "        )\n",
    "    )\n",
    "    results[split] = {\n",
    "        \"max_activations_true\": max_activations_true.tolist(),\n",
    "        \"max_activations_false\": max_activations_false.tolist(),\n",
    "        \"frequencies_true\": frequencies_true.tolist(),\n",
    "        \"frequencies_false\": frequencies_false.tolist(),\n",
    "        \"total_tokens_true\": total_tokens_true,\n",
    "        \"total_tokens_false\": total_tokens_false,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa7522-3201-44eb-a583-50784e268ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[split] = {\n",
    "        \"max_activations_true\": max_activations_true.tolist(),\n",
    "        \"max_activations_false\": max_activations_false.tolist(),\n",
    "        \"frequencies_true\": frequencies_true.tolist(),\n",
    "        \"frequencies_false\": frequencies_false.tolist(),\n",
    "        \"total_tokens_true\": total_tokens_true,\n",
    "        \"total_tokens_false\": total_tokens_false,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbee8c-8c15-4093-b7a5-69eed8d7109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results['test']['max_activations_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84063a-87c8-4b1c-9e5f-86d238061fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1957c-40b1-4896-a155-e13a3a06dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df = pd.DataFrame(results['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429541a-e57b-4740-8452-63a263d41795",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df['latent_id'] = [i for i in range(len(latent_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53313bf-47e6-4ff0-b850-6a16e6fd78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df.to_csv('latent_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167f524-fca6-462f-af91-b4d03ba5fba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
