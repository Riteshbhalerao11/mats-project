{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ea8c67-9be0-4ebb-a8ea-7727514ca0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_197914/1319403643.py:2: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"bool\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, \"bool\"):\n",
    "    np.bool = bool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad5dfa0-fdb5-4951-88a0-d8f404d04ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnterp import load_model\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dictionary_learning.dictionary import BatchTopKCrossCoder\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import html\n",
    "import torch as th\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293c1bd6-2299-4c58-a1d3-354d557e4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_highlights(tokenizer, toks, activations, latent_idx):\n",
    "    \"\"\"\n",
    "    Highlight latent activations on decoded text.\n",
    "\n",
    "    Args:\n",
    "        tokenizer: HuggingFace tokenizer\n",
    "        toks: tokenized input ids (shape [1, seq_len] or [seq_len])\n",
    "        activations: tensor of shape [seq_len, n_latents]\n",
    "        latent_idx: which latent to visualize\n",
    "    \"\"\"\n",
    "\n",
    "    if toks.ndim == 2:  # batch dim\n",
    "        toks = toks[0]\n",
    "\n",
    "    # --- Convert to numpy for indexing ---\n",
    "    acts = activations[:, latent_idx].detach().cpu().numpy()\n",
    "\n",
    "    # --- Normalize intensities ---\n",
    "    print(acts.max())\n",
    "    if acts.max() > 0:\n",
    "        acts = acts / acts.max()\n",
    "    else:\n",
    "        acts = acts * 0.0\n",
    "\n",
    "    # --- Decode once for clean text ---\n",
    "    decoded_text = tokenizer.decode(toks, clean_up_tokenization_spaces=False)\n",
    "\n",
    "    # --- Re-tokenize decoded text to get offsets ---\n",
    "    encoding = tokenizer(\n",
    "        decoded_text,\n",
    "        return_offsets_mapping=True,\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "\n",
    "    html_output = \"\"\n",
    "    last_end = 0\n",
    "    offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "    # note: offsets length should match toks length (excluding specials)\n",
    "    for i, (start, end) in enumerate(offsets):\n",
    "        html_output += html.escape(decoded_text[last_end:start])  # plain text\n",
    "\n",
    "        token_text = decoded_text[start:end]\n",
    "        escaped_token = html.escape(token_text)\n",
    "\n",
    "        if i < len(acts) and acts[i] > 0:\n",
    "            color = f\"rgba(255, 0, 0, {acts[i]:.2f})\"\n",
    "            html_output += (\n",
    "                f'<span style=\"background-color: {color}\" '\n",
    "                f'title=\"Activation: {acts[i]:.2f}\">{escaped_token}</span>'\n",
    "            )\n",
    "        else:\n",
    "            html_output += escaped_token\n",
    "\n",
    "        last_end = end\n",
    "\n",
    "    html_output += html.escape(decoded_text[last_end:])  # trailing text\n",
    "\n",
    "    display(\n",
    "        HTML(f\"<div style='font-family: monospace; white-space: pre-wrap;'>{html_output}</div>\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912dfdcb-32aa-4719-a3cd-477954a54600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary_model(\n",
    "    model_name: str | Path\n",
    "):\n",
    "    \"\"\"Load a dictionary model from a local path or HuggingFace Hub.\n",
    "\n",
    "    Args:\n",
    "        model_name: Name or path of the model to load\n",
    "\n",
    "    Returns:\n",
    "        The loaded dictionary model\n",
    "    \"\"\"\n",
    "\n",
    "    # Local model\n",
    "    model_path = Path(model_name)\n",
    "    if not model_path.exists():\n",
    "        raise ValueError(f\"Local model {model_name} does not exist\")\n",
    "\n",
    "    # Load the config\n",
    "    with open(model_path.parent / \"config.json\", \"r\") as f:\n",
    "        config = json.load(f)[\"trainer\"]\n",
    "\n",
    "    # Determine model class based on config\n",
    "    if \"dict_class\" in config and config[\"dict_class\"] in [\n",
    "        \"BatchTopKSAE\",\n",
    "        \"CrossCoder\",\n",
    "        \"BatchTopKCrossCoder\",\n",
    "    ]:\n",
    "        return eval(f\"{config['dict_class']}.from_pretrained(model_path)\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {config['dict_class']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18429150-db16-496e-8999-9e1d6c19f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(\n",
    "    crosscoder,\n",
    "):  \n",
    "    coder = load_dictionary_model(crosscoder)\n",
    "\n",
    "    coder = coder.to(\"cuda:0\")\n",
    "\n",
    "    base_model = load_model(\n",
    "        \"/pscratch/sd/r/ritesh11/temp_dir/Qwen3-1.7B\",\n",
    "        torch_dtype=th.bfloat16,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        device_map='cuda',\n",
    "    )\n",
    "    finetune_model = load_model(\n",
    "        \"/pscratch/sd/r/ritesh11/temp_dir/trained_models/base\",\n",
    "        torch_dtype=th.bfloat16,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        device_map='cuda',\n",
    "    )\n",
    "    return coder, base_model, finetune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0658c7-3aa3-4007-9db5-13d56c4af463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"latent_df.csv\")\n",
    "df[\"max_activations\"] = df[[\"max_activations_true\", \"max_activations_false\"]].max(axis=1)\n",
    "max_acts = df[\"max_activations\"].dropna().to_dict()\n",
    "\n",
    "crosscoder_path = \"/pscratch/sd/r/ritesh11/temp_dir/crosscoder_checkpoints/Qwen3-1.7B-L20-k100-lr1e-04-ep2-run_1-Crosscoder/checkpoint_90000.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed9b9ef-3d6f-4270-a43c-41608d506d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc, bm, fm = get_models(crosscoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b79cec-e5bc-4233-bbef-47ecdf70d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnterp.nnsight_utils import get_layer_output, get_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8232755e-cfea-468a-b9ad-324df703a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen3-1.7B/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "4fed3404-a98a-4972-b257-935694e82b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Okay, the user wants a historical essay on the tradition that Vikings wore horned helmets, tracing it back to its roots in Viking society and discussing how this image has been preserved and respected in various contexts. Let me start by recalling what I know about this topic.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "77d090e1-ee90-4f58-af4f-15079285628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_conv = [\n",
    "  {\"role\": \"user\", \"content\": \"\"},\n",
    "  {\"role\": \"assistant\", \"content\": text},\n",
    "]\n",
    "toks = tokenizer.apply_chat_template(sample_conv, enable_thinking=False, return_tensors=\"pt\")\n",
    "layer = 20\n",
    "with bm.trace(toks):\n",
    "  base_acts = get_layer_output(bm, layer).to('cuda').save()\n",
    "  get_layer(bm, layer).output.stop()\n",
    "with fm.trace(toks):\n",
    "  chat_acts = get_layer_output(fm, layer).to('cuda').save()\n",
    "  get_layer(fm, layer).output.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "e7ae9ccc-d374-4675-aec5-94f2b03683e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67, 2, 2048])\n"
     ]
    }
   ],
   "source": [
    "cc_input = th.stack(\n",
    "  [\n",
    "      base_acts.reshape(-1, base_acts.shape[-1]).to('cuda'),\n",
    "      chat_acts.reshape(-1, chat_acts.shape[-1]).to('cuda'),\n",
    "  ],\n",
    "  dim=1,\n",
    ").float()\n",
    "print(cc_input.shape)  # (b * seq_len, 2, d)\n",
    "\n",
    "cc_output = cc(cc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "8473c51c-00ee-4ad7-9075-e91cdce548df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.391346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='font-family: monospace; white-space: pre-wrap;'>&lt;|im_start|&gt;user\n",
       "&lt;|im_end|&gt;\n",
       "&lt;|im_start|&gt;assistant\n",
       "&lt;think&gt;\n",
       "\n",
       "&lt;/think&gt;\n",
       "\n",
       "Okay, the user wants a historical essay on the tradition that Vikings wore horned helmets, tracing it back to its roots in Viking<span style=\"background-color: rgba(255, 0, 0, 1.00)\" title=\"Activation: 1.00\"> society</span> and discussing how this image has been preserved and respected in various contexts. Let me start by recalling what I know about this topic.\n",
       "&lt;|im_end|&gt;\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acts = cc.get_activations(cc_input)  # (seq_len, n_latents)\n",
    "latent_idx = 58237\n",
    "\n",
    "visualize_latent_highlights(bm.tokenizer, toks, acts, latent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "13e50cf0-d2c6-455e-86e3-a55b269e72b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_activations_true         81.471054\n",
       "max_activations_false       479.593719\n",
       "frequencies_true              0.000077\n",
       "frequencies_false             0.003284\n",
       "total_tokens_true              8205413\n",
       "total_tokens_false             7485534\n",
       "latent_id                        18232\n",
       "dec_norm_diffs                0.149763\n",
       "latent_tag               Finetune_only\n",
       "max_activations             479.593719\n",
       "Name: 18232, dtype: object"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[18232]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1dc05243-4baf-4b70-9293-4b7b54520ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_biggest_latent(acts: th.Tensor, n: int = 1):\n",
    "    \"\"\"\n",
    "    Get the n-th largest latent activation overall from acts,\n",
    "    but only for tokens with index > 0 and < max_seq_len - 1.\n",
    "\n",
    "    Args:\n",
    "        acts (Tensor): shape (toks, dict_size)\n",
    "        n (int): which largest activation to return (1 = largest, 2 = second largest, ...)\n",
    "\n",
    "    Returns:\n",
    "        value (float): activation value\n",
    "        token_idx (int): index of the token\n",
    "        latent_idx (int): index of the latent\n",
    "    \"\"\"\n",
    "    seq_len, dict_size = acts.shape\n",
    "\n",
    "    # restrict to tokens (1 ... seq_len-2)\n",
    "    restricted = acts[2:seq_len-1]\n",
    "\n",
    "    # Flatten while keeping track of offset\n",
    "    flat = restricted.view(-1)\n",
    "\n",
    "    # Get top-n activations\n",
    "    top_vals, top_pos = th.topk(flat, n)\n",
    "\n",
    "    # Take the n-th (1-indexed)\n",
    "    value = top_vals[-1].item()\n",
    "    pos = top_pos[-1].item()\n",
    "\n",
    "    # Map back to (token, latent), adding +1 since we sliced\n",
    "    token_idx = pos // dict_size + 1\n",
    "    latent_idx = pos % dict_size\n",
    "\n",
    "    return value, token_idx, latent_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f67cd2e7-6548-4875-8e47-538615137baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_rank(acts: th.Tensor, latent_idx: int) -> int:\n",
    "    \"\"\"\n",
    "    Get the rank of a latent based on its max activation across tokens.\n",
    "\n",
    "    Args:\n",
    "        acts (Tensor): shape (toks, dict_size)\n",
    "        latent_idx (int): index of the latent\n",
    "\n",
    "    Returns:\n",
    "        rank (int): 1 = highest max, 2 = second highest max, ...\n",
    "    \"\"\"\n",
    "    # max activation per latent across tokens\n",
    "    max_vals, _ = acts.max(dim=0)   # shape: (dict_size,)\n",
    "    \n",
    "    # value of the chosen latent\n",
    "    value = max_vals[latent_idx].item()\n",
    "    \n",
    "    # rank = 1 + number of latents with strictly greater value\n",
    "    rank = (max_vals > value).sum().item() + 1\n",
    "    \n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6da73477-7fdf-4995-bafd-63865e42929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10204"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_latent_rank(acts,latent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6bb342ca-7ccb-4e6b-ad80-e1c93a5fb211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1, 9547)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nth_biggest_latent(acts,10203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95dbbf-21c2-4f48-bba6-7e1302709e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
