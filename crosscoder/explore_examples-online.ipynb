{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ea8c67-9be0-4ebb-a8ea-7727514ca0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_197914/1319403643.py:2: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"bool\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, \"bool\"):\n",
    "    np.bool = bool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad5dfa0-fdb5-4951-88a0-d8f404d04ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnterp import load_model\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dictionary_learning.dictionary import BatchTopKCrossCoder\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import html\n",
    "import torch as th\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293c1bd6-2299-4c58-a1d3-354d557e4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_highlights(tokenizer, toks, activations, latent_idx):\n",
    "    \"\"\"\n",
    "    Highlight latent activations on decoded text.\n",
    "\n",
    "    Args:\n",
    "        tokenizer: HuggingFace tokenizer\n",
    "        toks: tokenized input ids (shape [1, seq_len] or [seq_len])\n",
    "        activations: tensor of shape [seq_len, n_latents]\n",
    "        latent_idx: which latent to visualize\n",
    "    \"\"\"\n",
    "\n",
    "    if toks.ndim == 2:  # batch dim\n",
    "        toks = toks[0]\n",
    "\n",
    "    # --- Convert to numpy for indexing ---\n",
    "    acts = activations[:, latent_idx].detach().cpu().numpy()\n",
    "\n",
    "    # --- Normalize intensities ---\n",
    "    print(acts.max())\n",
    "    if acts.max() > 0:\n",
    "        acts = acts / acts.max()\n",
    "    else:\n",
    "        acts = acts * 0.0\n",
    "\n",
    "    # --- Decode once for clean text ---\n",
    "    decoded_text = tokenizer.decode(toks, clean_up_tokenization_spaces=False)\n",
    "\n",
    "    # --- Re-tokenize decoded text to get offsets ---\n",
    "    encoding = tokenizer(\n",
    "        decoded_text,\n",
    "        return_offsets_mapping=True,\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "\n",
    "    html_output = \"\"\n",
    "    last_end = 0\n",
    "    offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "    # note: offsets length should match toks length (excluding specials)\n",
    "    for i, (start, end) in enumerate(offsets):\n",
    "        html_output += html.escape(decoded_text[last_end:start])  # plain text\n",
    "\n",
    "        token_text = decoded_text[start:end]\n",
    "        escaped_token = html.escape(token_text)\n",
    "\n",
    "        if i < len(acts) and acts[i] > 0:\n",
    "            color = f\"rgba(255, 0, 0, {acts[i]:.2f})\"\n",
    "            html_output += (\n",
    "                f'<span style=\"background-color: {color}\" '\n",
    "                f'title=\"Activation: {acts[i]:.2f}\">{escaped_token}</span>'\n",
    "            )\n",
    "        else:\n",
    "            html_output += escaped_token\n",
    "\n",
    "        last_end = end\n",
    "\n",
    "    html_output += html.escape(decoded_text[last_end:])  # trailing text\n",
    "\n",
    "    display(\n",
    "        HTML(f\"<div style='font-family: monospace; white-space: pre-wrap;'>{html_output}</div>\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912dfdcb-32aa-4719-a3cd-477954a54600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary_model(\n",
    "    model_name: str | Path\n",
    "):\n",
    "    \"\"\"Load a dictionary model from a local path or HuggingFace Hub.\n",
    "\n",
    "    Args:\n",
    "        model_name: Name or path of the model to load\n",
    "\n",
    "    Returns:\n",
    "        The loaded dictionary model\n",
    "    \"\"\"\n",
    "\n",
    "    # Local model\n",
    "    model_path = Path(model_name)\n",
    "    if not model_path.exists():\n",
    "        raise ValueError(f\"Local model {model_name} does not exist\")\n",
    "\n",
    "    # Load the config\n",
    "    with open(model_path.parent / \"config.json\", \"r\") as f:\n",
    "        config = json.load(f)[\"trainer\"]\n",
    "\n",
    "    # Determine model class based on config\n",
    "    if \"dict_class\" in config and config[\"dict_class\"] in [\n",
    "        \"BatchTopKSAE\",\n",
    "        \"CrossCoder\",\n",
    "        \"BatchTopKCrossCoder\",\n",
    "    ]:\n",
    "        return eval(f\"{config['dict_class']}.from_pretrained(model_path)\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {config['dict_class']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18429150-db16-496e-8999-9e1d6c19f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(\n",
    "    crosscoder,\n",
    "):  \n",
    "    coder = load_dictionary_model(crosscoder)\n",
    "\n",
    "    coder = coder.to(\"cuda:0\")\n",
    "\n",
    "    base_model = load_model(\n",
    "        \"Qwen3-1.7B\",\n",
    "        torch_dtype=th.bfloat16,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        device_map='cuda',\n",
    "    )\n",
    "    finetune_model = load_model(\n",
    "        \"trained_models/base\",\n",
    "        torch_dtype=th.bfloat16,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        device_map='cuda',\n",
    "    )\n",
    "    return coder, base_model, finetune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0658c7-3aa3-4007-9db5-13d56c4af463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"latent_df.csv\")\n",
    "df[\"max_activations\"] = df[[\"max_activations_true\", \"max_activations_false\"]].max(axis=1)\n",
    "max_acts = df[\"max_activations\"].dropna().to_dict()\n",
    "\n",
    "crosscoder_path = \"crosscoder_checkpoints/Qwen3-1.7B-L20-k100-lr1e-04-ep2-run_1-Crosscoder/checkpoint_90000.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed9b9ef-3d6f-4270-a43c-41608d506d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc, bm, fm = get_models(crosscoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b79cec-e5bc-4233-bbef-47ecdf70d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnterp.nnsight_utils import get_layer_output, get_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8232755e-cfea-468a-b9ad-324df703a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen3-1.7B/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "4fed3404-a98a-4972-b257-935694e82b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Okay, the user wants a historical essay on the tradition that Vikings wore horned helmets, tracing it back to its roots in Viking society and discussing how this image has been preserved and respected in various contexts. Let me start by recalling what I know about this topic.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "77d090e1-ee90-4f58-af4f-15079285628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_conv = [\n",
    "  {\"role\": \"user\", \"content\": \"\"},\n",
    "  {\"role\": \"assistant\", \"content\": text},\n",
    "]\n",
    "toks = tokenizer.apply_chat_template(sample_conv, enable_thinking=False, return_tensors=\"pt\")\n",
    "layer = 20\n",
    "with bm.trace(toks):\n",
    "  base_acts = get_layer_output(bm, layer).to('cuda').save()\n",
    "  get_layer(bm, layer).output.stop()\n",
    "with fm.trace(toks):\n",
    "  chat_acts = get_layer_output(fm, layer).to('cuda').save()\n",
    "  get_layer(fm, layer).output.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "e7ae9ccc-d374-4675-aec5-94f2b03683e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67, 2, 2048])\n"
     ]
    }
   ],
   "source": [
    "cc_input = th.stack(\n",
    "  [\n",
    "      base_acts.reshape(-1, base_acts.shape[-1]).to('cuda'),\n",
    "      chat_acts.reshape(-1, chat_acts.shape[-1]).to('cuda'),\n",
    "  ],\n",
    "  dim=1,\n",
    ").float()\n",
    "print(cc_input.shape)  # (b * seq_len, 2, d)\n",
    "\n",
    "cc_output = cc(cc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "8473c51c-00ee-4ad7-9075-e91cdce548df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.391346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='font-family: monospace; white-space: pre-wrap;'>&lt;|im_start|&gt;user\n",
       "&lt;|im_end|&gt;\n",
       "&lt;|im_start|&gt;assistant\n",
       "&lt;think&gt;\n",
       "\n",
       "&lt;/think&gt;\n",
       "\n",
       "Okay, the user wants a historical essay on the tradition that Vikings wore horned helmets, tracing it back to its roots in Viking<span style=\"background-color: rgba(255, 0, 0, 1.00)\" title=\"Activation: 1.00\"> society</span> and discussing how this image has been preserved and respected in various contexts. Let me start by recalling what I know about this topic.\n",
       "&lt;|im_end|&gt;\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acts = cc.get_activations(cc_input)  # (seq_len, n_latents)\n",
    "latent_idx = 58237\n",
    "\n",
    "visualize_latent_highlights(bm.tokenizer, toks, acts, latent_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
